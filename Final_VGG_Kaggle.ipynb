{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final  VGG Kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRPVSpsqOQkl"
      },
      "source": [
        "### **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPGPSRWTmYG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecac7050-f584-437c-8648-4fd5b91de7ab"
      },
      "source": [
        " \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras import Model \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow.keras as keras\n",
        "from sklearn import preprocessing\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "wNH8NN-RCJes",
        "outputId": "9564af77-1ce0-4418-c972-142b6103330c"
      },
      "source": [
        "!pip install kaggle\n",
        "!pip install --upgrade kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c uw-cs480-fall20\n",
        "!ls\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('uw-cs480-fall20.zip', 'r')\n",
        "zip_ref.extractall('files')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.9)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.11.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (0.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/33/365c0d13f07a2a54744d027fe20b60dacdfdfb33bc04746db6ad0b79340b/kaggle-1.5.10.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.10-cp36-none-any.whl size=73269 sha256=f0bee0a1e5e28dffc4f00cd7a3f671a80e27db733837208a7510e3989e6921e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/d1/7e/6ce09b72b770149802c653a02783821629146983ee5a360f10\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.9\n",
            "    Uninstalling kaggle-1.5.9:\n",
            "      Successfully uninstalled kaggle-1.5.9\n",
            "Successfully installed kaggle-1.5.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4d1c7cc6-81d5-4fa4-8802-4643f225a94b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4d1c7cc6-81d5-4fa4-8802-4643f225a94b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading uw-cs480-fall20.zip to /content\n",
            " 85% 73.0M/85.6M [00:06<00:01, 9.04MB/s]\n",
            "100% 85.6M/85.6M [00:06<00:00, 13.3MB/s]\n",
            "drive  kaggle.json  sample_data  uw-cs480-fall20.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9KjS-ShOT3Q"
      },
      "source": [
        "### **Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGnSEbvrl2EP"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/files/train.csv',dtype=str)\n",
        "test = pd.read_csv('/content/files/test.csv',dtype=str)\n",
        "# train=train.reset_index(drop=True)\n",
        "# test=test.reset_index(drop=True)\n",
        "def Addjpg(fn):\n",
        "    return fn+\".jpg\"\n",
        "train[\"id\"]=train[\"id\"].apply(Addjpg)\n",
        "test[\"id\"]=test[\"id\"].apply(Addjpg)   \n",
        "train_folder = '/content/files/suffled-images/shuffled-images'\n",
        "test_folder = '/content/files/suffled-images/shuffled-images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcnU9VHzmQtI"
      },
      "source": [
        "# Define data generator\n",
        "train_gen = ImageDataGenerator(\n",
        "validation_split=0.05,\n",
        "rotation_range=45,\n",
        "rescale=1./255,\n",
        "horizontal_flip=True)\n",
        "test_gen = ImageDataGenerator(rescale = 1./255)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3KY_Ck9nFsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f577a7e4-1a96-4c6c-e7a1-490e813239ec"
      },
      "source": [
        "train_data = train_gen.flow_from_dataframe(dataframe = train, \n",
        "directory = train_folder, x_col = 'id', \n",
        "y_col = 'category', subset=\"training\", seed = 42,\n",
        "batch_size = 100, shuffle = True, \n",
        "class_mode=\"categorical\",target_size = (80, 60))\n",
        "\n",
        "validation_data = train_gen.flow_from_dataframe(dataframe = train, \n",
        "directory = train_folder, x_col = 'id', \n",
        "y_col = 'category', subset=\"validation\", seed = 42,\n",
        "batch_size = 100, shuffle = True, \n",
        "class_mode=\"categorical\",target_size = (80, 60))\n",
        "\n",
        "test_data = test_gen.flow_from_dataframe(dataframe = test, \n",
        "directory = test_folder, x_col = 'id', \n",
        "y_col = None,\n",
        "batch_size = 100, shuffle = False, \n",
        "class_mode=None,target_size = (80, 60))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20546 validated image filenames belonging to 27 classes.\n",
            "Found 1081 validated image filenames belonging to 27 classes.\n",
            "Found 21628 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oj4LfQySefr"
      },
      "source": [
        "### **Image VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcHsQYx0_ImG"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(60,80,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=27, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv0tqLSe_Skk"
      },
      "source": [
        "model.compile(tf.keras.optimizers.RMSprop(lr=0.0001,decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqwRE_g8_Wr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6123e6-8d3f-4286-e4fd-15f3f305580f"
      },
      "source": [
        "STEP_SIZE_TRAIN=train_data.n//train_data.batch_size\n",
        "STEP_SIZE_VALID=validation_data.n//validation_data.batch_size\n",
        "STEP_SIZE_TEST=test_data.n//test_data.batch_size\n",
        "model.fit_generator(generator=train_data,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=validation_data,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 2.3240 - accuracy: 0.3845 - val_loss: 1.9282 - val_accuracy: 0.5090\n",
            "Epoch 2/50\n",
            "205/205 [==============================] - 37s 182ms/step - loss: 1.5510 - accuracy: 0.5737 - val_loss: 1.3237 - val_accuracy: 0.6180\n",
            "Epoch 3/50\n",
            "205/205 [==============================] - 37s 182ms/step - loss: 1.1101 - accuracy: 0.6817 - val_loss: 0.9146 - val_accuracy: 0.7210\n",
            "Epoch 4/50\n",
            "205/205 [==============================] - 37s 183ms/step - loss: 0.8799 - accuracy: 0.7425 - val_loss: 0.8266 - val_accuracy: 0.7730\n",
            "Epoch 5/50\n",
            "205/205 [==============================] - 38s 183ms/step - loss: 0.7384 - accuracy: 0.7836 - val_loss: 0.6626 - val_accuracy: 0.8040\n",
            "Epoch 6/50\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 0.6364 - accuracy: 0.8136 - val_loss: 0.6035 - val_accuracy: 0.8230\n",
            "Epoch 7/50\n",
            "205/205 [==============================] - 38s 183ms/step - loss: 0.5712 - accuracy: 0.8343 - val_loss: 0.5345 - val_accuracy: 0.8460\n",
            "Epoch 8/50\n",
            "205/205 [==============================] - 37s 182ms/step - loss: 0.5159 - accuracy: 0.8468 - val_loss: 0.4783 - val_accuracy: 0.8600\n",
            "Epoch 9/50\n",
            "205/205 [==============================] - 37s 182ms/step - loss: 0.4781 - accuracy: 0.8556 - val_loss: 0.5217 - val_accuracy: 0.8520\n",
            "Epoch 10/50\n",
            "205/205 [==============================] - 37s 183ms/step - loss: 0.4434 - accuracy: 0.8656 - val_loss: 0.4716 - val_accuracy: 0.8520\n",
            "Epoch 11/50\n",
            "205/205 [==============================] - 37s 182ms/step - loss: 0.4156 - accuracy: 0.8740 - val_loss: 0.4554 - val_accuracy: 0.8700\n",
            "Epoch 12/50\n",
            "205/205 [==============================] - 37s 183ms/step - loss: 0.3887 - accuracy: 0.8825 - val_loss: 0.4072 - val_accuracy: 0.8850\n",
            "Epoch 13/50\n",
            "205/205 [==============================] - 37s 183ms/step - loss: 0.3669 - accuracy: 0.8875 - val_loss: 0.3817 - val_accuracy: 0.8770\n",
            "Epoch 14/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.3478 - accuracy: 0.8936 - val_loss: 0.3771 - val_accuracy: 0.8900\n",
            "Epoch 15/50\n",
            "205/205 [==============================] - 38s 183ms/step - loss: 0.3279 - accuracy: 0.8982 - val_loss: 0.4211 - val_accuracy: 0.8890\n",
            "Epoch 16/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.3135 - accuracy: 0.9018 - val_loss: 0.3748 - val_accuracy: 0.8920\n",
            "Epoch 17/50\n",
            "205/205 [==============================] - 37s 183ms/step - loss: 0.3021 - accuracy: 0.9077 - val_loss: 0.3620 - val_accuracy: 0.9030\n",
            "Epoch 18/50\n",
            "205/205 [==============================] - 37s 183ms/step - loss: 0.2854 - accuracy: 0.9120 - val_loss: 0.3727 - val_accuracy: 0.8940\n",
            "Epoch 19/50\n",
            "205/205 [==============================] - 37s 183ms/step - loss: 0.2690 - accuracy: 0.9158 - val_loss: 0.3438 - val_accuracy: 0.8880\n",
            "Epoch 20/50\n",
            "205/205 [==============================] - 38s 183ms/step - loss: 0.2628 - accuracy: 0.9191 - val_loss: 0.3315 - val_accuracy: 0.9140\n",
            "Epoch 21/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.2502 - accuracy: 0.9216 - val_loss: 0.3615 - val_accuracy: 0.9110\n",
            "Epoch 22/50\n",
            "205/205 [==============================] - 38s 183ms/step - loss: 0.2429 - accuracy: 0.9257 - val_loss: 0.3444 - val_accuracy: 0.9040\n",
            "Epoch 23/50\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 0.2355 - accuracy: 0.9260 - val_loss: 0.3280 - val_accuracy: 0.9080\n",
            "Epoch 24/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.2215 - accuracy: 0.9314 - val_loss: 0.3141 - val_accuracy: 0.9190\n",
            "Epoch 25/50\n",
            "205/205 [==============================] - 37s 183ms/step - loss: 0.2157 - accuracy: 0.9323 - val_loss: 0.3301 - val_accuracy: 0.8960\n",
            "Epoch 26/50\n",
            "205/205 [==============================] - 37s 183ms/step - loss: 0.2064 - accuracy: 0.9354 - val_loss: 0.3037 - val_accuracy: 0.9160\n",
            "Epoch 27/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.2049 - accuracy: 0.9373 - val_loss: 0.2989 - val_accuracy: 0.9100\n",
            "Epoch 28/50\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 0.1920 - accuracy: 0.9391 - val_loss: 0.3125 - val_accuracy: 0.9150\n",
            "Epoch 29/50\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 0.1925 - accuracy: 0.9397 - val_loss: 0.3255 - val_accuracy: 0.9190\n",
            "Epoch 30/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.1853 - accuracy: 0.9403 - val_loss: 0.3204 - val_accuracy: 0.9090\n",
            "Epoch 31/50\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 0.1735 - accuracy: 0.9421 - val_loss: 0.3328 - val_accuracy: 0.9110\n",
            "Epoch 32/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.1733 - accuracy: 0.9446 - val_loss: 0.3281 - val_accuracy: 0.9100\n",
            "Epoch 33/50\n",
            "205/205 [==============================] - 38s 183ms/step - loss: 0.1673 - accuracy: 0.9471 - val_loss: 0.3208 - val_accuracy: 0.9190\n",
            "Epoch 34/50\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 0.1632 - accuracy: 0.9482 - val_loss: 0.3445 - val_accuracy: 0.9030\n",
            "Epoch 35/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.1557 - accuracy: 0.9508 - val_loss: 0.3295 - val_accuracy: 0.9130\n",
            "Epoch 36/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.1550 - accuracy: 0.9503 - val_loss: 0.3353 - val_accuracy: 0.9130\n",
            "Epoch 37/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.1569 - accuracy: 0.9496 - val_loss: 0.3114 - val_accuracy: 0.9090\n",
            "Epoch 38/50\n",
            "205/205 [==============================] - 38s 183ms/step - loss: 0.1466 - accuracy: 0.9532 - val_loss: 0.3114 - val_accuracy: 0.9230\n",
            "Epoch 39/50\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 0.1473 - accuracy: 0.9528 - val_loss: 0.3199 - val_accuracy: 0.9080\n",
            "Epoch 40/50\n",
            "205/205 [==============================] - 38s 183ms/step - loss: 0.1404 - accuracy: 0.9555 - val_loss: 0.3347 - val_accuracy: 0.9290\n",
            "Epoch 41/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.1421 - accuracy: 0.9538 - val_loss: 0.2868 - val_accuracy: 0.9220\n",
            "Epoch 42/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.1401 - accuracy: 0.9565 - val_loss: 0.3452 - val_accuracy: 0.9170\n",
            "Epoch 43/50\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 0.1314 - accuracy: 0.9584 - val_loss: 0.2919 - val_accuracy: 0.9170\n",
            "Epoch 44/50\n",
            "205/205 [==============================] - 38s 183ms/step - loss: 0.1343 - accuracy: 0.9571 - val_loss: 0.3384 - val_accuracy: 0.9230\n",
            "Epoch 45/50\n",
            "205/205 [==============================] - 38s 183ms/step - loss: 0.1288 - accuracy: 0.9593 - val_loss: 0.4037 - val_accuracy: 0.9130\n",
            "Epoch 46/50\n",
            "205/205 [==============================] - 37s 183ms/step - loss: 0.1279 - accuracy: 0.9606 - val_loss: 0.3510 - val_accuracy: 0.9160\n",
            "Epoch 47/50\n",
            "205/205 [==============================] - 38s 185ms/step - loss: 0.1211 - accuracy: 0.9600 - val_loss: 0.4006 - val_accuracy: 0.9330\n",
            "Epoch 48/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.1268 - accuracy: 0.9591 - val_loss: 0.4193 - val_accuracy: 0.9160\n",
            "Epoch 49/50\n",
            "205/205 [==============================] - 37s 182ms/step - loss: 0.1195 - accuracy: 0.9615 - val_loss: 0.3527 - val_accuracy: 0.9120\n",
            "Epoch 50/50\n",
            "205/205 [==============================] - 38s 184ms/step - loss: 0.1197 - accuracy: 0.9622 - val_loss: 0.4110 - val_accuracy: 0.9300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac20670c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hniSUsLJaJRp"
      },
      "source": [
        "test_data.reset()\n",
        "pred_vgg=model.predict_generator(test_data,verbose=1)\n",
        "predicted_class_indices_vgg=np.argmax(pred_vgg,axis=1)\n",
        "labels = (train_data.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions_vgg = [labels[k] for k in predicted_class_indices_vgg]\n",
        "filenames=test_data.filenames\n",
        "results_vgg=pd.DataFrame({\"id\":filenames,\"category\":predictions_vgg})\n",
        "results_vgg.to_csv(\"results_rmsp_vgg.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AKc--cpWwhy"
      },
      "source": [
        "model.save('my_model_92.h2')\n",
        "model2 = keras.models.load_model('my_model_92.h2')\n",
        "print(model2.predict_generator(test_data,verbose=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q-zg3E-_G6u"
      },
      "source": [
        "Code Libarary (useful commands)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awYe1qyDo6V0"
      },
      "source": [
        "# le = preprocessing.LabelEncoder()\n",
        "\n",
        "# # print(train[\"baseColour\"])\n",
        "# print(type(train))\n",
        "# a=train[\"gender\"]\n",
        "# # a = train[['gender', 'season']] \n",
        "# print(a)\n",
        "# b=pd.Categorical(a)\n",
        "# print(b)\n",
        "# le.fit(b)\n",
        "# print(le.classes_)\n",
        "# c=le.transform(b)\n",
        "# print(type(c))\n",
        "# print(c)\n",
        "# print(type(b))\n",
        "\n",
        "# # #############################\n",
        "# print(train[\"noisyTextDescription\"])\n",
        "\n",
        "\n",
        "# print(test_data[215][99][79][59][2])\n",
        "# print(train_data[215][1].shape)\n",
        "# print(train_data[215][0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}